- Long sequence time-series forecasting (**LSTF**)-----长序列时间预测
- Long Short-Term Memory（**LSTM**）-----长短期记忆网络：是一种时间循环神经网络，是为了解决一般的[RNN](https://baike.baidu.com/item/RNN/5707183?fromModule=lemma_inlink)（[循环神经网络](https://baike.baidu.com/item/循环神经网络/23199490?fromModule=lemma_inlink)）存在的长期依赖问题而专门设计出来的，所有的RNN都具有一种重复神经网络模块的链式形式。在标准RNN中，这个重复的结构模块只有一个非常简单的结构，例如一个tanh层。
- Backpropagation Through Time  (**BPTT**) ----反向传播通过时间：是一种用于训练递归神经网络（RNN）的算法，旨在解决传统反向传播算法在处理长期依赖问题时的不足。其基本思想是将时间视为一个维度，通过时间展开网络结构，并在每个时间步上进行反向传播。
- Auxiliary Losses ---辅助损失：是在神经网络中使用多个损失函数的一种策略。这一策略的目的是通过在网络中引入**额外的损失函数**来提供额外的优化目标，以改善模型的性能或加速训练过程。辅助损失通常与主要损失函数一起使用，主要损失函数通常与任务的主要目标相关。
- Recurrent Highway Networks （RNN）----循环高速网络：结合了RNN中的循环更新和highway connections（高速门控机制，其中高速门控机制为**carry gate（携带门）** 和 **transform gate（变换门）**)
- Bootstrapping Regularizer --- 自举正则化:是一种在训练过程中，将模型预测与真实标签混合，用于降低噪声并提升稳定性的技术。
- k-Nearest Neighbors（k-NN）：是一种 **基于实例的监督学习算法**，常用于分类和回归。1）给定一个新的数据点，计算它与训练集中所有样本的距离（常用欧氏距离、曼哈顿距离等）。2）选出距离最近的 **k 个邻居**。3）分类任务：取这 k 个邻居中 **多数类别** 作为预测结果。4）回归任务：取这 k 个邻居的 **平均值/加权平均值** 作为预测结果。

