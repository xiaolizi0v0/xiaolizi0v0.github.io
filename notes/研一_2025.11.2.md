### DiM: Improving multivariate time series forecasting with DI embedding andmulti-head graph learning mechanism[DiM: Improving multivariate time series forecasting with DI embedding and multi-head graph learning mechanism - ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S092523122502449X#preview-section-references)
#### 多元时间序列（MTS）

它由多个单变量时间序列组成，每个单变量时间序列代表一个具有独特时间动态的独立通道。此外，这些通过通过复杂的关系相互关联。如下图所示。

<img src="..\image\image-20251102204641810.png" alt="image-20251102204641810" />

#### 本文贡献

1.提出了一种DI时间嵌入策略，该策略将差异嵌入与现有的方向嵌入方法相结合，增强了模型捕捉时间动态的能力。

2.针对当前图学习的局限性，收多头注意力的启发，开发了一种多头图学习机制，能够更准确地识别通道间的关系，为传统的基于注意力的方法提供了一种可靠的替代方案

3.提出了DiM，是一种基于图神经网络（GNN）的多变量时间序列预测模型，它融合了DI嵌入和多头图学习机制。

#### 多变量时间序列预测嵌入方法

**Informer** , **Autoformer** , **Pyraformer** , and **FEDformer** 只是简单的把多特征通道做合并，可能会引入噪声并降低性能。为了解决这个问题，有人提出了**PatchTST**采用了一种补丁嵌入方法。而**iTransformer**提出了一种倒置嵌入方法。然而这些方法主要依赖线性映射，可能无法捕捉应时间影响下的动态通道关系。为了更能够获得通道之间的时间信息，后续讲究人员引入了注意力嵌入，如**sTransformer**通过时间卷积网络TCN替代线性映射，解决 了倒置嵌入方法的缺点。同时，**MTPNet**提出了一种维度不变的卷积神经网络CNN嵌入，通过卷积操作明确保留跨通道的时间动态和空间依赖性。此外，**PRfomer**利用金字塔循环卷积网络RNN嵌入来获取融合多尺度依赖信息的时间序列表示，增强了模型捕捉复杂时间动态的能力。但是本身的计算需求较大。

#### 多时间序列预测的通道间关系建模

解耦通道之间复杂的依赖关系对于多变量时间序列预测至关重要，LSTNet采用卷积神经网络捕捉通道之间关系，并利用循环神经